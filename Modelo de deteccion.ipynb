{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Modelo de deteccion.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carlo1911/deeplearning/blob/master/Modelo%20de%20deteccion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcFkIgHM4wAW",
        "colab_type": "text"
      },
      "source": [
        "# Segmentación de instancias\n",
        "Se realiza una demostración del entrenamiento del modelo a utilizar en el proyecto porque el tiempo real es muy extenso ya que se usa el conjunto de datos COCO."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuwTpJEw5LWk",
        "colab_type": "text"
      },
      "source": [
        "## Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdUXPeD44o4k",
        "colab_type": "code",
        "colab": {},
        "outputId": "5802e20e-0af7-4d01-b876-da833369cd25"
      },
      "source": [
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from pycocotools import mask as maskUtils\n",
        "\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import requests\n",
        "import os\n",
        "import sys\n",
        "import imgaug\n",
        "\n",
        "#Cargamos librerias externas\n",
        "ROOT_DIR = os.path.abspath(\"./libraries/\")\n",
        "sys.path.append(ROOT_DIR)\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"../mask_rcnn_coco.h5\")\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okDD816V5Ocr",
        "colab_type": "text"
      },
      "source": [
        "## Conjunto de datos\n",
        "Se realiza la definición y la carga del conjunto de datos COCO para el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqjvbB2N4o4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CocoDataset(utils.Dataset):\n",
        "    def load_coco(self, subset):\n",
        "        #Debemos descargar antes las annotations de la pagina de COCO\n",
        "        coco = COCO(\"./annotations/instances_{}{}.json\".format(subset, 2017))\n",
        "        image_dir = \"./images/{}\".format(subset)\n",
        "        image_ids = []\n",
        "        image_ids.extend(list(coco.getImgIds(catIds=[1]))) #Solo Cargamos el subset de Personas\n",
        "        \n",
        "        image_ids = image_ids[0:1]\n",
        "        \n",
        "        \n",
        "        for i in image_ids:\n",
        "            #Descargamos las imagenes para usarlas en el entrenamiento\n",
        "            img_data = requests.get(coco.imgs[i]['coco_url']).content\n",
        "            exist = os.path.isfile(image_dir + '/' + coco.imgs[i]['file_name'])\n",
        "            if not exist:             \n",
        "                with open(image_dir + '/' + coco.imgs[i]['file_name'], 'wb') as handler:\n",
        "                    handler.write(img_data)\n",
        "            \n",
        "            self.add_image(\"coco\", image_id=i, path=os.path.join(image_dir, coco.imgs[i]['file_name']),\n",
        "                width=coco.imgs[i][\"width\"], height=coco.imgs[i][\"height\"], \n",
        "                annotations=coco.loadAnns(coco.getAnnIds(imgIds=[i], catIds=[1], iscrowd=None)))\n",
        "        \n",
        "        self.add_class(\"coco\", 1, 'person')\n",
        "\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        image_info = self.image_info[image_id]\n",
        "\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "        annotations = self.image_info[image_id][\"annotations\"]\n",
        "\n",
        "        for annotation in annotations:\n",
        "            class_id = self.map_source_class_id(\"coco.{}\".format(annotation['category_id']))\n",
        "            if class_id == 1:\n",
        "                m = self.annToMask(annotation, image_info[\"height\"], image_info[\"width\"])\n",
        "                if m.max() < 1:\n",
        "                    continue\n",
        "\n",
        "                if annotation['iscrowd']:\n",
        "                    class_id *= -1\n",
        "                    if m.shape[0] != image_info[\"height\"] or m.shape[1] != image_info[\"width\"]:\n",
        "                        m = np.ones([image_info[\"height\"], image_info[\"width\"]], dtype=bool)\n",
        "                instance_masks.append(m)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        if class_ids:\n",
        "            mask = np.stack(instance_masks, axis=2).astype(np.bool)\n",
        "            class_ids = np.array(class_ids, dtype=np.int32)\n",
        "            return mask, class_ids\n",
        "        else:\n",
        "            return super(CocoDataset, self).load_mask(image_id)\n",
        "\n",
        "\n",
        "    def annToRLE(self, ann, height, width):\n",
        "        segm = ann['segmentation']\n",
        "        if isinstance(segm, list):\n",
        "            rles = maskUtils.frPyObjects(segm, height, width)\n",
        "            rle = maskUtils.merge(rles)\n",
        "        elif isinstance(segm['counts'], list):\n",
        "            rle = maskUtils.frPyObjects(segm, height, width)\n",
        "        else:\n",
        "            rle = ann['segmentation']\n",
        "        return rle\n",
        "\n",
        "    def annToMask(self, ann, height, width):\n",
        "        rle = self.annToRLE(ann, height, width)\n",
        "        m = maskUtils.decode(rle)\n",
        "        return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPblygZ25hGi",
        "colab_type": "text"
      },
      "source": [
        "## Visualización de configuración"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8dmBWKm4o4r",
        "colab_type": "code",
        "colab": {},
        "outputId": "34f31e21-07e9-4ad7-ab4a-a94b54cda8c5"
      },
      "source": [
        "class CocoConfig(Config):\n",
        "    NAME = \"coco\"\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 5\n",
        "    NUM_CLASSES = 2\n",
        "\n",
        "config = CocoConfig()\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     5\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 5\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           coco\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1000\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIET4GUv5n9M",
        "colab_type": "text"
      },
      "source": [
        "## Separación del conjunto de datos\n",
        "Se separa el conjunto de datos en entrenamiento y validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rSyiBGs4o4u",
        "colab_type": "code",
        "colab": {},
        "outputId": "338c1f1b-853c-40ad-c57d-58b15cfe091b"
      },
      "source": [
        "dataset_train = CocoDataset()\n",
        "dataset_train.load_coco(\"train\")\n",
        "dataset_train.prepare()\n",
        "\n",
        "dataset_val = CocoDataset()\n",
        "dataset_val.load_coco(\"val\")\n",
        "dataset_val.prepare()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=13.30s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.36s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er9XPPoq50TZ",
        "colab_type": "text"
      },
      "source": [
        "## Definición del modelo\n",
        "Se carga el modelo Mask R-CNN y los pesos para el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlLkyV6y4o4w",
        "colab_type": "code",
        "colab": {},
        "outputId": "75b551f3-84aa-4008-cec4-40148a9d47f5"
      },
      "source": [
        "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=DEFAULT_LOGS_DIR)\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=['mrcnn_bbox_fc', 'mrcnn_class_logits','mrcnn_mask'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /Users/ddiestra/Documents/Projects/deeplearning/libraries/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/Documents/Projects/deeplearning/libraries/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/Documents/Projects/deeplearning/libraries/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8_o0ibu6Hdm",
        "colab_type": "text"
      },
      "source": [
        "## Proceso de entrenamiento\n",
        "Se muestra el intento de entrenamiento con del modelo con el conjunto de datos COCO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "560jtUSY4o4y",
        "colab_type": "code",
        "colab": {},
        "outputId": "c084ec4d-9e1b-4b69-b728-4ed9c9c22196"
      },
      "source": [
        "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
        "\n",
        "# Entrenamiento - 1\n",
        "# Entrenamiento de cabeceras\n",
        "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE, epochs=10, layers='heads', augmentation=augmentation)\n",
        "\n",
        "# Entrenamiento - 2\n",
        "# Ajuste de parámetros en capa 4 a +\n",
        "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE, epochs=30, layers='4+', augmentation=augmentation)\n",
        "\n",
        "# Entrenamiento - 3\n",
        "# Ajuste de parámetros en general\n",
        "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE / 10, epochs=40, layers='all', augmentation=augmentation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training network heads\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /Users/ddiestra/Documents/Projects/deeplearning/libraries/logs/coco20200716T0031/mask_rcnn_coco_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/10\n",
            " 416/1000 [===========>..................] - ETA: 11:38:12 - loss: 0.2086 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.0212 - mrcnn_class_loss: 0.0138 - mrcnn_bbox_loss: 0.0292 - mrcnn_mask_loss: 0.1400"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-20:\n",
            "Process ForkPoolWorker-18:\n",
            "Process ForkPoolWorker-15:\n",
            "Process ForkPoolWorker-3:\n",
            "Process ForkPoolWorker-10:\n",
            "Process ForkPoolWorker-1:\n",
            "Process ForkPoolWorker-5:\n",
            "Process ForkPoolWorker-22:\n",
            "Process ForkPoolWorker-8:\n",
            "Process ForkPoolWorker-24:\n",
            "Process ForkPoolWorker-6:\n",
            "Process ForkPoolWorker-13:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Process ForkPoolWorker-17:\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/Users/ddiestra/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}